{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy, scipy, matplotlib.pyplot as plt, pandas as pd\n",
    "import sklearn, IPython.display as ipd\n",
    "import librosa, librosa.display\n",
    "import itertools\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from pathlib import Path\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC, SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Retrieve Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c1_signals = []\n",
    "# counter=0\n",
    "# for p in Path().glob('audio/train/c1/*.mp3'):\n",
    "#     counter=counter+1\n",
    "#     if counter > 10:\n",
    "#         break\n",
    "#     else:\n",
    "#         c1_signals.append(librosa.load(p, duration=30, offset=10)[0])\n",
    "\n",
    "# c2_signals = []\n",
    "# counter=0\n",
    "# for p in Path().glob('audio/train/c2/*.mp3'):\n",
    "#     counter=counter+1\n",
    "#     if counter > 10:\n",
    "#         break\n",
    "#     else:\n",
    "#         c2_signals.append(librosa.load(p, duration=30, offset=10)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_signals = [\n",
    "    librosa.load(p, duration=30, offset=10)[0] for p in Path().glob('audio/train/c1/*.mp3')\n",
    "]\n",
    "c2_signals = [\n",
    "    librosa.load(p, duration=30, offset=10)[0] for p in Path().glob('audio/train/c2/*.mp3')\n",
    "]\n",
    "c3_signals = [\n",
    "    librosa.load(p, duration=30, offset=10)[0] for p in Path().glob('audio/train/c3/*.mp3')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "100\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(c1_signals))\n",
    "print(len(c2_signals))\n",
    "print(len(c3_signals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mfcc = 12\n",
    "hop_length = 512\n",
    "def extract_features(signal):\n",
    "    zcr = librosa.feature.zero_crossing_rate(signal).mean()\n",
    "    cent = librosa.feature.spectral_centroid(signal).mean()\n",
    "    mfccs = librosa.feature.mfcc(signal, n_mfcc=n_mfcc).mean()\n",
    "    S = librosa.feature.melspectrogram(signal).mean()\n",
    "    tempo = librosa.feature.tempogram(signal, hop_length=hop_length).mean()\n",
    "    rmse = librosa.feature.rmse(signal, hop_length=hop_length).mean()\n",
    "    chroma = librosa.feature.chroma_stft(signal).mean()\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(signal).mean()\n",
    "    return [zcr, cent, mfccs, S, tempo, rmse, chroma, spec_bw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kameswar/anaconda3/lib/python3.6/site-packages/librosa/core/audio.py:574: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.pad((y_sign[slice_post] != y_sign[slice_pre]),\n",
      "/home/kameswar/anaconda3/lib/python3.6/site-packages/librosa/util/utils.py:1377: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  data_agg[idx_agg] = aggregate(data[idx_in], axis=axis)\n",
      "/home/kameswar/anaconda3/lib/python3.6/site-packages/scipy/fftpack/basic.py:160: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  z[index] = x\n",
      "/home/kameswar/anaconda3/lib/python3.6/site-packages/librosa/core/audio.py:447: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  autocorr = autocorr[subslice]\n",
      "/home/kameswar/anaconda3/lib/python3.6/site-packages/librosa/util/utils.py:826: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return (x > x_pad[inds1]) & (x >= x_pad[inds2])\n"
     ]
    }
   ],
   "source": [
    "c1_features = np.array([extract_features(x) for x in c1_signals])\n",
    "c2_features = np.array([extract_features(x) for x in c2_signals])\n",
    "c3_features = np.array([extract_features(x) for x in c3_signals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 8)\n",
      "(100, 8)\n",
      "(100, 8)\n"
     ]
    }
   ],
   "source": [
    "print(c1_features.shape)\n",
    "print(c2_features.shape)\n",
    "print(c3_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.23336744 -0.08948801  0.12649063 -0.51290256 -0.15395375 -0.21921891\n",
      " -0.27510573 -0.09310684]\n",
      "[0.46218705 0.38335149 0.46212865 0.37861044 0.43241216 0.38094568\n",
      " 0.35045076 0.35457033]\n",
      "[-0.36488162  0.16760711  0.11460639 -0.72234962 -0.07585366 -0.52252048\n",
      " -0.01492442  0.48434216]\n",
      "[0.57286357 0.505123   0.56765696 0.28821355 0.53063895 0.32892931\n",
      " 0.43578074 0.32568216]\n",
      "[-0.4866333   0.05015285  0.32460485 -0.37878482 -0.1698694  -0.20072424\n",
      "  0.07717739  0.35776427]\n",
      "[0.47097336 0.41518885 0.58328218 0.55828309 0.55116693 0.44234508\n",
      " 0.57474021 0.3051282 ]\n"
     ]
    }
   ],
   "source": [
    "#scaler = sklearn.preprocessing.StandardScaler()\n",
    "scaler = sklearn.preprocessing.MinMaxScaler(feature_range=(-1, 1))\n",
    "\n",
    "c1_features_scaled = scaler.fit_transform(c1_features)\n",
    "print(c1_features_scaled.mean(axis=0))\n",
    "print(c1_features_scaled.std(axis=0))\n",
    "\n",
    "c2_features_scaled = scaler.transform(c2_features)\n",
    "print(c2_features_scaled.mean(axis=0))\n",
    "print(c2_features_scaled.std(axis=0))\n",
    "\n",
    "c3_features_scaled = scaler.transform(c3_features)\n",
    "print(c3_features_scaled.mean(axis=0))\n",
    "print(c3_features_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 8)\n",
      "[-1.50562137 -1.         -1.35085151 -1.01270722 -1.06488029 -1.07418495\n",
      " -1.         -1.        ]\n",
      "[1.5849273  1.81745481 1.22350598 1.67416138 1.36919755 1.\n",
      " 2.0117758  1.09160228]\n"
     ]
    }
   ],
   "source": [
    "train_features = numpy.vstack((c1_features_scaled, c2_features_scaled, c3_features_scaled))\n",
    "print(train_features.shape)\n",
    "print(train_features.min(axis=0))\n",
    "print(train_features.max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = numpy.concatenate((numpy.zeros(len(c1_features_scaled)), numpy.ones(len(c2_features_scaled)), numpy.full(len(c3_features_scaled),2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
      " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 0 0 1 1 1 1 1 1 0 1 2 0 0 0 2 0 1 0 2 1 1 1 2 0 1 0 0 2 1 0 1 1 1\n",
      " 2 0 1 2 1 0 0 1 1 2 1 0 1 2 0 0 1 1 1 1 0 0 1 0 2 2 2 2 1 1 1 0 1 1 2 0 1\n",
      " 2 1 1 1 2 1 1 0 1 2 1 1 1 1 1 2 1 1 1 1 0 1 1 0 2 1 2 2 0 2 1 2 2 0 1 1 1\n",
      " 2 0 1 1 1 2 1 0 1 2 1 2 2 1 1 2 2 0 1 1 1 0 1 2 2 1 1 2 0 0 0 1 0 1 2 0 0\n",
      " 1 0 2 0 0 0 2 2 2 1 2 0 2 1 0 2 0 1 2 1 2 0 2 0 0 2 2 0 1 2 1 0 1 2 0 1 1\n",
      " 2 1 0 1 1 1 2 2 2 2 1 1 2 1 0 2 1 0 0 1 1 1 1 0 0 0 2 0 1 2 0 0 1 0 1 2 0\n",
      " 2 1 1 0 2 0 0 2 1 1 1 0 2 2 2 2 0 1 0 1 0 0 1 0 1 2 1 0 0 1 0 0 0 0 0 1 0\n",
      " 1 1 0 0 0 2 0 0 0 1 0 1 1 0 2 1 0 0 1 0 1 2 0 2 1 0 2 0 0 1 0 0 0 0 1 0 2\n",
      " 0 2 0 0]\n"
     ]
    }
   ],
   "source": [
    "model = sklearn.cluster.KMeans(n_clusters=3)\n",
    "labels = model.fit_predict(train_features)\n",
    "print (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2733333333333333"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = accuracy_score(train_labels, labels)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "# svc = sklearn.svm.SVC()\n",
    "# model = GridSearchCV(svc, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {'weights':('uniform', 'distance'), 'n_neighbors':[1, 3, 5, 7]}\n",
    "# knn = sklearn.neighbors.KNeighborsClassifier()\n",
    "# model = GridSearchCV(knn, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters = {'solver':('newton-cg', 'lbfgs', 'sag', 'saga')}\n",
    "# reg = sklearn.linear_model.LogisticRegression()\n",
    "# model = GridSearchCV(reg, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = sklearn.svm.SVC()\n",
    "#model = sklearn.neighbors.KNeighborsClassifier(n_neighbors=5)\n",
    "#model = sklearn.linear_model.LogisticRegression()\n",
    "#model = sklearn.tree.DecisionTreeClassifier()\n",
    "#model = sklearn.naive_bayes.GaussianNB()\n",
    "#model = sklearn.linear_model.SGDClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OneVsRest\n",
    "# X,y = train_features, train_labels\n",
    "# y_true = test_labels\n",
    "# model = OneVsRestClassifier(sklearn.linear_model.LogisticRegression(random_state=0)).fit(X, y)\n",
    "# model.predict(X)\n",
    "# model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc  = sklearn.model_selection.cross_val_score(model, train_features, train_labels, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('acc =', acc)\n",
    "print ('acc mean =',acc.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c1_test_signals = []\n",
    "# counter=0\n",
    "# for p in Path().glob('audio/test/c1/*.mp3'):\n",
    "#     counter=counter+1\n",
    "#     if counter > 2:\n",
    "#         break\n",
    "#     else:\n",
    "#         c1_test_signals.append(librosa.load(p, duration=30, offset=60)[0])\n",
    "\n",
    "# c2_test_signals = []\n",
    "# counter=0\n",
    "# for p in Path().glob('audio/test/c2/*.mp3'):\n",
    "#     counter=counter+1\n",
    "#     if counter > 2:\n",
    "#         break\n",
    "#     else:\n",
    "#         c2_test_signals.append(librosa.load(p, duration=30, offset=60)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_test_signals = [\n",
    "    librosa.load(p, duration=30, offset=60)[0] for p in Path().glob('audio/test/c1/*.mp3')\n",
    "]\n",
    "c2_test_signals = [\n",
    "    librosa.load(p, duration=30, offset=60)[0] for p in Path().glob('audio/test/c2/*.mp3')\n",
    "]\n",
    "c3_test_signals = [\n",
    "    librosa.load(p, duration=30, offset=60)[0] for p in Path().glob('audio/test/c3/*.mp3')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(c1_test_signals))\n",
    "print(len(c2_test_signals))\n",
    "print(len(c3_test_signals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_test_features = numpy.array([extract_features(x) for x in c1_test_signals])\n",
    "c2_test_features = numpy.array([extract_features(x) for x in c2_test_signals])\n",
    "c3_test_features = numpy.array([extract_features(x) for x in c3_test_signals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c1_test_features.shape)\n",
    "print(c2_test_features.shape)\n",
    "print(c3_test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_test_features_scaled = scaler.transform(c1_test_features)\n",
    "c2_test_features_scaled = scaler.transform(c2_test_features)\n",
    "c3_test_features_scaled = scaler.transform(c3_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = numpy.vstack((c1_test_features_scaled, c2_test_features_scaled, c3_test_features_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = numpy.concatenate((numpy.zeros(len(c1_test_features)), numpy.ones(len(c2_test_features)), np.full(len(c2_test_features), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels = model.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.score(test_features, test_labels)\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "cohen_kappa = cohen_kappa_score(test_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_metrics = [score, accuracy, cohen_kappa]\n",
    "classification_metrics_labels = ['score', 'accuracy', 'cohen_kappa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(classification_metrics, classification_metrics_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(test_labels, predicted_labels)\n",
    "explained_variance_score = explained_variance_score(test_labels, predicted_labels)\n",
    "mean_squared_error = mean_squared_error(test_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_metrics = [r2, explained_variance_score, mean_squared_error]\n",
    "regression_metrics_labels = ['r2_score', 'explained_variance_score', 'mean_squared_error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(regression_metrics, regression_metrics_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "class_names = [0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(test_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(test_labels, predicted_labels)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
